{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('input.txt', 'r').read()\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data)):\n",
    "#     data[i] = data[i].strip(\"\\n\").lower()   \n",
    "# # remove all elements in data which are empty strings\n",
    "# data = list(filter(None, data))\n",
    "# len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# for name in data:\n",
    "#     for word in name.split():\n",
    "#         words.append(word)\n",
    "# len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: '\\n',\n",
       "  1: ' ',\n",
       "  2: '!',\n",
       "  3: '$',\n",
       "  4: '&',\n",
       "  5: \"'\",\n",
       "  6: ',',\n",
       "  7: '-',\n",
       "  8: '.',\n",
       "  9: '3',\n",
       "  10: ':',\n",
       "  11: ';',\n",
       "  12: '?',\n",
       "  13: 'A',\n",
       "  14: 'B',\n",
       "  15: 'C',\n",
       "  16: 'D',\n",
       "  17: 'E',\n",
       "  18: 'F',\n",
       "  19: 'G',\n",
       "  20: 'H',\n",
       "  21: 'I',\n",
       "  22: 'J',\n",
       "  23: 'K',\n",
       "  24: 'L',\n",
       "  25: 'M',\n",
       "  26: 'N',\n",
       "  27: 'O',\n",
       "  28: 'P',\n",
       "  29: 'Q',\n",
       "  30: 'R',\n",
       "  31: 'S',\n",
       "  32: 'T',\n",
       "  33: 'U',\n",
       "  34: 'V',\n",
       "  35: 'W',\n",
       "  36: 'X',\n",
       "  37: 'Y',\n",
       "  38: 'Z',\n",
       "  39: 'a',\n",
       "  40: 'b',\n",
       "  41: 'c',\n",
       "  42: 'd',\n",
       "  43: 'e',\n",
       "  44: 'f',\n",
       "  45: 'g',\n",
       "  46: 'h',\n",
       "  47: 'i',\n",
       "  48: 'j',\n",
       "  49: 'k',\n",
       "  50: 'l',\n",
       "  51: 'm',\n",
       "  52: 'n',\n",
       "  53: 'o',\n",
       "  54: 'p',\n",
       "  55: 'q',\n",
       "  56: 'r',\n",
       "  57: 's',\n",
       "  58: 't',\n",
       "  59: 'u',\n",
       "  60: 'v',\n",
       "  61: 'w',\n",
       "  62: 'x',\n",
       "  63: 'y',\n",
       "  64: 'z'},\n",
       " {'\\n': 0,\n",
       "  ' ': 1,\n",
       "  '!': 2,\n",
       "  '$': 3,\n",
       "  '&': 4,\n",
       "  \"'\": 5,\n",
       "  ',': 6,\n",
       "  '-': 7,\n",
       "  '.': 8,\n",
       "  '3': 9,\n",
       "  ':': 10,\n",
       "  ';': 11,\n",
       "  '?': 12,\n",
       "  'A': 13,\n",
       "  'B': 14,\n",
       "  'C': 15,\n",
       "  'D': 16,\n",
       "  'E': 17,\n",
       "  'F': 18,\n",
       "  'G': 19,\n",
       "  'H': 20,\n",
       "  'I': 21,\n",
       "  'J': 22,\n",
       "  'K': 23,\n",
       "  'L': 24,\n",
       "  'M': 25,\n",
       "  'N': 26,\n",
       "  'O': 27,\n",
       "  'P': 28,\n",
       "  'Q': 29,\n",
       "  'R': 30,\n",
       "  'S': 31,\n",
       "  'T': 32,\n",
       "  'U': 33,\n",
       "  'V': 34,\n",
       "  'W': 35,\n",
       "  'X': 36,\n",
       "  'Y': 37,\n",
       "  'Z': 38,\n",
       "  'a': 39,\n",
       "  'b': 40,\n",
       "  'c': 41,\n",
       "  'd': 42,\n",
       "  'e': 43,\n",
       "  'f': 44,\n",
       "  'g': 45,\n",
       "  'h': 46,\n",
       "  'i': 47,\n",
       "  'j': 48,\n",
       "  'k': 49,\n",
       "  'l': 50,\n",
       "  'm': 51,\n",
       "  'n': 52,\n",
       "  'o': 53,\n",
       "  'p': 54,\n",
       "  'q': 55,\n",
       "  'r': 56,\n",
       "  's': 57,\n",
       "  't': 58,\n",
       "  'u': 59,\n",
       "  'v': 60,\n",
       "  'w': 61,\n",
       "  'x': 62,\n",
       "  'y': 63,\n",
       "  'z': 64})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars = list(set(''.join(data)))\n",
    "unique_chars.sort()\n",
    "vocab_dict = {i:ch for i, ch in enumerate(unique_chars)}\n",
    "vocab_dict_inv = {ch:i for i, ch in enumerate(unique_chars)}\n",
    "vocab_dict, vocab_dict_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "# X, Y = [], []\n",
    "# for w in words[:]:\n",
    "#   context = [0] * block_size\n",
    "#   for ch in w + ' ':\n",
    "#     ix = vocab_dict_inv[ch]\n",
    "#     X.append(context)\n",
    "#     Y.append(ix)\n",
    "#     print(''.join(vocab_dict[i] for i in context), '--->', vocab_dict[ix])\n",
    "#     context = context[1:] + [ix] # crop and append\n",
    "# X = torch.tensor(X)\n",
    "# Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "block_size = 8\n",
    "for i in range(0, len(data)-block_size, 1):\n",
    "    X.append([vocab_dict_inv[ch] for ch in data[i:i+block_size]])\n",
    "    Y.append(vocab_dict_inv[data[i+block_size]])\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Ci ---> t\n"
     ]
    }
   ],
   "source": [
    "for i in range(block_size):\n",
    "    print(''.join(vocab_dict[X[0][i].item()]), end='')\n",
    "print(' --->', vocab_dict[Y[0].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1115386, 8]), torch.int64, torch.Size([1115386]), torch.int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer for the context\n",
    "\n",
    "emb_dim = 8\n",
    "emb = torch.nn.Embedding(len(vocab_dict), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4224, -0.2301, -0.6769,  2.2439,  1.5449, -0.2505,  1.4018,  0.8653],\n",
       "        [ 0.1172, -0.5490,  0.5780, -0.4085, -0.3632, -0.4643, -0.3646, -1.1857],\n",
       "        [-0.3266, -1.0644, -0.8176,  0.0199, -0.8590,  0.1450,  2.0973, -1.1745],\n",
       "        [ 0.9968, -0.4266, -1.6335,  0.5124, -0.3232, -0.9523, -0.8851,  0.8337],\n",
       "        [ 1.8732,  1.8775, -1.3940,  0.4830, -1.0210,  0.6431,  0.2027, -1.1337],\n",
       "        [-1.3270,  0.6844,  0.4294,  0.9266, -0.4439,  1.2226, -0.1170, -0.5448],\n",
       "        [ 0.2748,  0.7771,  0.8583, -0.0324, -0.7477, -0.7011,  2.1690, -0.5316],\n",
       "        [ 0.3910, -0.4883, -0.6890, -1.5744,  0.0135,  1.1290,  0.1272,  0.4126],\n",
       "        [ 1.9219,  0.6136,  1.7254, -0.6341,  1.2452,  1.1339, -1.2551,  1.2101],\n",
       "        [ 0.7103, -0.0643,  0.5063,  1.4917,  0.4359,  1.1978,  0.4778, -0.6312],\n",
       "        [-2.2179,  1.0802,  0.1278, -0.6601,  1.5522,  0.0524, -0.8309,  0.6377],\n",
       "        [-0.3293,  1.5548, -3.0348,  0.0055, -1.0085, -1.2164, -0.2199, -1.3688],\n",
       "        [-0.0336,  1.0863,  0.0922,  0.0378, -1.6876, -0.6344,  1.1086, -0.8917],\n",
       "        [ 0.3012,  0.5595,  0.5783, -2.2308, -1.7815, -0.3331,  0.2224,  0.1214],\n",
       "        [ 0.7958,  0.6070,  1.3097,  0.6427,  0.1102, -0.0828,  1.5816, -2.2658],\n",
       "        [-1.4871, -2.5132, -1.9219, -0.4978,  0.8638,  0.6112,  0.3197,  0.5964],\n",
       "        [-0.6984,  0.0177, -1.4840, -0.1826, -0.0175, -0.8203,  1.2354,  1.0028],\n",
       "        [ 0.8947,  1.1479, -0.8321, -1.6863,  0.5499,  1.0339,  0.4818, -0.0878],\n",
       "        [-0.8843, -1.7678,  1.2412, -1.1187, -0.4899,  0.4745,  1.7718,  0.1204],\n",
       "        [ 0.4568, -1.1842, -0.2123,  2.1506,  0.9124, -1.1212,  0.9989,  0.1314],\n",
       "        [ 0.4934, -1.5564,  0.6640,  1.4067, -1.7901, -0.2795,  1.1508, -0.3288],\n",
       "        [-1.1148, -0.5921, -1.5352, -1.6026,  0.7364,  1.9636,  0.2072, -0.2749],\n",
       "        [ 0.3995,  0.4043,  0.8275,  0.4334,  0.5593, -1.8737,  1.1457, -2.8593],\n",
       "        [ 0.7628, -0.5902, -0.0782, -0.6666, -0.2295, -0.8375, -0.6553, -1.0329],\n",
       "        [-1.2020, -1.1256, -0.2263, -0.5929, -0.5619,  0.9646, -0.3000,  0.6692],\n",
       "        [-1.0252, -0.7427, -0.6600, -1.0192, -1.3725,  0.7656, -0.2606,  0.3496],\n",
       "        [-1.2088, -0.6119, -0.9471,  0.9346, -0.5631, -1.2505, -0.4680,  0.6294],\n",
       "        [ 1.3615,  1.0982, -0.4907, -1.1663, -0.6790,  1.2535,  0.4404, -0.1671],\n",
       "        [-1.5976,  1.3025,  0.4594,  0.0346, -1.6025,  0.4710,  0.5509, -0.9631],\n",
       "        [ 1.9318, -0.3649,  0.8442, -0.2864,  1.7051,  0.8111, -0.1345,  1.1605],\n",
       "        [-1.9034,  2.0709, -0.7922,  0.3736,  1.3079,  0.9698, -0.1020,  0.1655],\n",
       "        [ 0.4976, -1.6036,  0.4091, -0.7240,  1.9356, -1.3869,  1.3566,  0.0938],\n",
       "        [ 0.4093,  0.8204,  1.1859, -0.0927,  0.6603, -0.0710,  1.8748, -2.0063],\n",
       "        [-0.0973,  1.7579, -0.3700,  0.3109, -1.3155, -0.6003,  0.2203,  0.3886],\n",
       "        [-2.7325, -1.9360,  1.3445, -0.3406,  1.6919,  0.3662,  1.1982, -1.3241],\n",
       "        [-1.4079, -0.3359, -0.7932,  0.0377,  0.4833,  1.1188, -1.4977, -1.6730],\n",
       "        [ 1.6079, -0.8518, -0.7988, -2.8487,  1.2349, -1.2272, -0.5290,  0.0179],\n",
       "        [-0.1782, -0.8833, -0.3003, -0.0161,  0.9995, -0.5957, -0.0484, -0.2144],\n",
       "        [-3.2771,  0.7083,  0.5421,  0.0817,  1.5466,  0.1417, -0.2713,  0.9255],\n",
       "        [ 1.6853,  0.5152, -0.8873, -0.2536,  0.6298, -0.6767, -0.5683,  1.2123],\n",
       "        [ 0.0196, -1.4954, -0.3355,  0.7565, -0.1154, -0.4898, -0.3984, -0.6971],\n",
       "        [-0.4003,  0.3347, -0.0876,  0.5487, -1.3540,  0.1800, -0.2716, -2.2247],\n",
       "        [ 0.2226, -1.0664,  1.7406, -1.4424,  1.8735, -1.7368,  0.6235, -0.5214],\n",
       "        [-0.2601,  1.1023, -0.5609, -0.6949, -1.1972,  1.6107, -1.6657, -0.2342],\n",
       "        [ 0.1901,  0.0861,  0.0059,  1.0498,  0.8763,  0.8233, -1.3276,  1.4730],\n",
       "        [ 0.6338,  0.3134,  0.6297,  0.0067, -1.2072,  0.4598, -1.1456,  0.0547],\n",
       "        [ 0.2574,  1.4510, -2.1152, -0.7145,  0.1591,  0.5729, -0.2840,  1.0654],\n",
       "        [-2.3654, -1.3344, -0.3874,  0.1772,  1.3246, -2.3937, -1.2235,  1.3445],\n",
       "        [ 0.2065,  0.0319,  0.2602,  2.1970,  0.4734,  0.6916,  0.2512,  0.0598],\n",
       "        [ 1.0597,  0.0977, -0.8392, -0.3799,  0.2593,  0.4710,  0.7778, -1.5669],\n",
       "        [ 0.7221, -1.1789,  0.3573, -0.6154,  0.2256,  1.4909, -0.1316, -0.7231],\n",
       "        [-1.7935, -0.6589, -0.5434, -0.6284,  0.9528, -1.2261, -0.7915,  1.2846],\n",
       "        [ 0.0932,  1.0595,  0.4627,  0.8403,  1.1213, -0.6835, -0.5164, -1.5152],\n",
       "        [ 0.2269, -1.8319,  2.6137,  0.6685,  0.5070, -0.6682,  1.7096, -1.1092],\n",
       "        [-0.3744,  1.3545, -0.6068, -0.8555,  0.0177, -0.3588, -0.9533, -0.0160],\n",
       "        [ 0.0237,  0.3859, -1.3797, -0.4328, -0.3787,  1.3756, -0.2518, -0.6456],\n",
       "        [-1.0705, -0.4220,  0.5204,  0.1138,  0.5970, -0.8205,  1.4450,  1.7332],\n",
       "        [ 0.0712,  0.1160,  0.6772, -0.9299, -0.3133, -0.6702, -0.6071, -1.5834],\n",
       "        [ 1.4226, -1.5519, -0.5644, -0.2885,  1.1842, -0.5109, -0.7042,  1.3667],\n",
       "        [ 0.7038,  0.6062, -0.2710,  0.5544,  0.6969,  0.2884, -1.2296, -0.7646],\n",
       "        [ 0.4447, -0.5753, -0.2968,  2.3820, -0.3559, -0.5998,  0.0381,  0.6041],\n",
       "        [-1.0129,  1.6075,  2.9942,  0.8026, -1.6889, -0.1521, -0.7097, -1.0657],\n",
       "        [-1.8215,  0.4865,  0.5017, -0.8590, -0.3282, -0.4580, -0.9738,  0.8523],\n",
       "        [-0.5514,  0.0916,  0.5453,  0.3883,  0.1736,  0.8622, -0.2109,  1.1403],\n",
       "        [ 0.3595,  0.7408, -0.7807,  0.0970,  0.3528,  1.2883, -0.4399, -0.3974]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextChar(nn.Module):\n",
    "  def __init__(self, block_size, vocab_size, emb_dim, hidden_dims = [block_size * emb_dim, block_size * emb_dim]):\n",
    "    super().__init__()\n",
    "    self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "    self.lin1 = nn.Linear(block_size * emb_dim, hidden_dims[0])\n",
    "    self.lin2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "    self.lin3 = nn.Linear(hidden_dims[1], vocab_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.emb(x)\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = torch.sin(self.lin1(x))\n",
    "    x = torch.sin(self.lin2(x))\n",
    "    x = self.lin3(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nokxLu&OhNqw\n"
     ]
    }
   ],
   "source": [
    "# Generate names from untrained model\n",
    "\n",
    "\n",
    "model = NextChar(block_size, len(vocab_dict), emb_dim).to(device)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(4000002)\n",
    "def generate_name(model,sentence, itos, stoi, block_size, max_len=10):\n",
    "    original_sentence = sentence\n",
    "    if len(sentence) < block_size:\n",
    "        sentence = \" \" * (block_size - len(sentence)) + sentence\n",
    "    using_for_predicction = sentence[-block_size:].lower()\n",
    "    context = [stoi[word] for word in using_for_predicction]\n",
    "    prediction = \"\"\n",
    "    for i in range(max_len):\n",
    "        x = torch.tensor(context).view(1, -1).to(device)\n",
    "        y_pred = model(x)\n",
    "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
    "        ch = itos[ix]\n",
    "        prediction += ch\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "    return original_sentence + prediction\n",
    "\n",
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight torch.Size([65, 8])\n",
      "lin1.weight torch.Size([64, 64])\n",
      "lin1.bias torch.Size([64])\n",
      "lin2.weight torch.Size([64, 64])\n",
      "lin2.bias torch.Size([64])\n",
      "lin3.weight torch.Size([65, 64])\n",
      "lin3.bias torch.Size([65])\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(param_name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.02109956741333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vannshjani/Desktop/text_gen.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x \u001b[39m=\u001b[39m X[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y \u001b[39m=\u001b[39m Y[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/vannshjani/Desktop/text_gen.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin1(x))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin2(x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin3(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# loss with logits\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "import time\n",
    "# Mini-batch training\n",
    "batch_size = 4096\n",
    "print_every = 100\n",
    "elapsed_time = []\n",
    "for epoch in range(10000):\n",
    "    start_time = time.time()\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        x = X[i:i+batch_size]\n",
    "        y = Y[i:i+batch_size]\n",
    "        y_pred = model(x)\n",
    "    \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    end_time = time.time()\n",
    "    elapsed_time.append(end_time - start_time)\n",
    "    if epoch % print_every == 0:\n",
    "        print(epoch, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size,100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning knobs\n",
    "\n",
    "1. Embedding size\n",
    "2. MLP \n",
    "3. Context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Downloads/model.pth\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NextChar(block_size, len(vocab_dict), emb_dim).to(device)\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, block_size, vocab_size, emb_dim, hidden_dims = [1024, 1024]):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dims[0], num_layers=2, batch_first=True,bias = True)\n",
    "        self.lin = nn.Linear(hidden_dims[0], vocab_size)\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x[:,-1,:]\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(block_size, len(vocab_dict), emb_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate names from untrained model\n",
    "\n",
    "# model = torch.compile(model)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(4000002)\n",
    "def generate_name(model,sentence, itos, stoi, block_size, max_len=10):\n",
    "    original_sentence = sentence\n",
    "    if len(sentence) < block_size:\n",
    "        sentence = \" \" * (block_size - len(sentence)) + sentence\n",
    "    using_for_predicction = sentence[-block_size:].lower()\n",
    "    context = [stoi[word] for word in using_for_predicction]\n",
    "    prediction = \"\"\n",
    "    for i in range(max_len):\n",
    "        x = torch.tensor(context).view(1, -1).to(device)\n",
    "        y_pred = model(x)\n",
    "        ix = torch.distributions.categorical.Categorical(logits=y_pred).sample().item()\n",
    "        ch = itos[ix]\n",
    "        prediction += ch\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "    return original_sentence + prediction\n",
    "\n",
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb.weight torch.Size([65, 8])\n",
      "lstm.weight_ih_l0 torch.Size([4096, 8])\n",
      "lstm.weight_hh_l0 torch.Size([4096, 1024])\n",
      "lstm.bias_ih_l0 torch.Size([4096])\n",
      "lstm.bias_hh_l0 torch.Size([4096])\n",
      "lstm.weight_ih_l1 torch.Size([4096, 1024])\n",
      "lstm.weight_hh_l1 torch.Size([4096, 1024])\n",
      "lstm.bias_ih_l1 torch.Size([4096])\n",
      "lstm.bias_hh_l1 torch.Size([4096])\n",
      "lin.weight torch.Size([65, 1024])\n",
      "lin.bias torch.Size([65])\n"
     ]
    }
   ],
   "source": [
    "for param_name, param in model.named_parameters():\n",
    "    print(param_name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vannshjani/Desktop/text_gen.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x \u001b[39m=\u001b[39m X[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m y \u001b[39m=\u001b[39m Y[i:i\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/vannshjani/Desktop/text_gen.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x \u001b[39m=\u001b[39m x[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vannshjani/Desktop/text_gen.ipynb#X43sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# loss with logits\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.01)\n",
    "import time\n",
    "# Mini-batch training\n",
    "batch_size = 4096\n",
    "print_every = 10\n",
    "elapsed_time = []\n",
    "for epoch in range(10000):\n",
    "    start_time = time.time()\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        x = X[i:i+batch_size]\n",
    "        y = Y[i:i+batch_size]\n",
    "        y_pred = model(x)\n",
    "    \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    end_time = time.time()\n",
    "    elapsed_time.append(end_time - start_time)\n",
    "    if epoch % print_every == 0:\n",
    "        print(epoch, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    want = input(\"Do you want to generate text? (yes/no): \")\n",
    "    if want == \"no\":\n",
    "        break\n",
    "    sentence = input(\"Enter a sentence: \")\n",
    "    print(generate_name(model,sentence, vocab_dict, vocab_dict_inv, block_size,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Downloads/model_lstm.pth\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(block_size, len(vocab_dict), emb_dim).to(device)\n",
    "model.load_state_dict(torch.load(path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
